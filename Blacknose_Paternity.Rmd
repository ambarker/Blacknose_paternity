---
title: "Blacknose Paternity Project"
output: 
  html_notebook: 
    highlight: kate
    theme: flatly
    toc: yes
---

Load libraries

```{r Load libraries}
library(ggplot2)
library(reshape2)
library(tidyr)
library(dplyr)
library(grid)
library(maps)
library(mapdata)
library(mapproj)
library(marmap)
library(GISTools)
```

#Paternity simulation results 

Import results from Paternity.V2. This python script calculates the minimum number of sires per litter (allele counting method) when using 1-21 markers. Every possible combination of loci was evaluated. Two loci were excluded from this analysis because PrDM can only handle up to 30 alleles per locus. Run 2 incorporated the requirement that at least 2 loci must support the minimum number of fathers. 

```{r import results}
paternity_mean1<- read.csv("~/Google Drive/Blacknose_Paternity_Project/python_paternity_results_1.txt")
paternity_mean2<- read.csv("~/Google Drive/Blacknose_Paternity_Project/python_paternity_results_2.txt")
```

Plot results:

```{r plot results, message=FALSE, error=FALSE}
# ggplot(paternity_mean1, aes(Num_Loci,Percent_multiple)) + 
#   geom_point()
tiff("Figure_2.tiff", height = 4, width = 6, units = "in", res = 600)
ggplot(paternity_mean2, aes(Num_Loci,Percent_multiple)) + 
  geom_point() + 
  xlab("Number of loci") + 
  ylab("Percent multiple paternity") +
  theme_classic() +
  theme(axis.text=element_text(size=12), axis.title=element_text(size=14))
dev.off()
```

## Redo python simulation with most/least polymorphic loci 

```{r}
paternity_polymorphism_AH5 <- read.csv("~/Dropbox/Python_BnoseV2/paternity_results_#A_H5.txt", header = FALSE, col.names="Percent_multiple") %>% mutate(Num_Loci = c(1:5), Category = "#A_H5")

paternity_polymorphism_AL5 <- read.csv("~/Dropbox/Python_BnoseV2/paternity_results_#A_L5.txt", header = FALSE, col.names="Percent_multiple") %>% mutate(Num_Loci = c(1:5), Category = "#A_L5")

paternity_polymorphism_AH10 <- read.csv("~/Dropbox/Python_BnoseV2/paternity_results_#A_H10.txt", header = FALSE, col.names="Percent_multiple") %>% mutate(Num_Loci = c(1:10), Category = "#A_H10")

paternity_polymorphism_AL10 <- read.csv("~/Dropbox/Python_BnoseV2/paternity_results_#A_L10.txt", header = FALSE, col.names="Percent_multiple") %>% mutate(Num_Loci = c(1:10), Category = "#A_L10")

paternity_polymorphism_HeH5 <- read.csv("~/Dropbox/Python_BnoseV2/paternity_results_He_H5.txt", header = FALSE, col.names="Percent_multiple") %>% mutate(Num_Loci = c(1:5), Category = "He_H5")

paternity_polymorphism_HeL5 <- read.csv("~/Dropbox/Python_BnoseV2/paternity_results_He_L5.txt", header = FALSE, col.names="Percent_multiple") %>% mutate(Num_Loci = c(1:5), Category = "He_L5")

paternity_polymorphism_HeH10 <- read.csv("~/Dropbox/Python_BnoseV2/paternity_results_He_H10.txt", header = FALSE, col.names="Percent_multiple") %>% mutate(Num_Loci = c(1:10), Category = "He_H10")

paternity_polymorphism_HeL10 <- read.csv("~/Dropbox/Python_BnoseV2/paternity_results_He_L10.txt", header = FALSE, col.names="Percent_multiple") %>% mutate(Num_Loci = c(1:10), Category = "He_L10")

paternity_polymorphism_A <- rbind(paternity_polymorphism_AH5, paternity_polymorphism_AL5, paternity_polymorphism_AH10, paternity_polymorphism_AL10)

paternity_polymorphism_He <- rbind(paternity_polymorphism_HeH5, paternity_polymorphism_HeL5, paternity_polymorphism_HeH10, paternity_polymorphism_HeL10)

paternity_polymorphism <- rbind(paternity_polymorphism_A, paternity_polymorphism_He)

```

```{r}
ggplot(paternity_polymorphism_A, aes(Num_Loci,Percent_multiple, group = Category)) + 
  geom_line(aes(shape = Category)) + 
  xlab("Number of loci") + 
  ylab("Percent multiple paternity") +
  theme_classic() +
  theme(axis.text=element_text(size=12), axis.title=element_text(size=14))

ggplot(paternity_polymorphism_He, aes(Num_Loci,Percent_multiple, Category)) + 
  geom_point(aes(shape = Category)) + 
  xlab("Number of loci") + 
  ylab("Percent multiple paternity") +
  theme_classic() +
  theme(axis.text=element_text(size=12), axis.title=element_text(size=14))

ggplot(paternity_polymorphism, aes(Num_Loci,Percent_multiple, group = Category)) + 
  geom_line(aes(group = Category, color = Category)) + 
  xlab("Number of loci") + 
  ylab("Percent multiple paternity") +
  theme_classic() +
  theme(axis.text=element_text(size=12), axis.title=element_text(size=14))
```

Make combined figure

```{r}
allele_diversity <- rbind(paternity_polymorphism_AH5, paternity_polymorphism_AL5)
paternity_mean2$Category <- "All"
combined <- rbind(allele_diversity, paternity_mean2)

tiff("Figure_2.tiff", height = 4, width = 6, units = "in", res = 600)
ggplot(combined, aes(Num_Loci,Percent_multiple)) + 
  geom_point(aes(shape = Category)) +
  xlab("Number of loci") + 
  ylab("Percent multiple paternity") +
  scale_shape_discrete(name = "Loci", labels = c("High diversity", "Low diversity", "All")) +
  theme_classic() +
  theme(axis.text=element_text(size=12), axis.title=element_text(size=14))
dev.off()
```


#PrDM simulation results

This simulation uses the program PrDM and a python script wrapper to calcualte the probability of detecting multiple paternity when using 1-23 markers. First uses a random 1 locus, random 2 loci, random 3 and so on up to 23 loci. 

2 fathers, 50:50 reproductive skew, 100 simulations:

```{r  2 fathers PrDM import results}
# import results
prdm_results_5050 <- read.table("~/Google Drive/Blacknose_Paternity_Project/PrDM_Sim_avg_results_2_50_50_x100.txt")
prdm_results_7525 <- read.table("~/Google Drive/Blacknose_Paternity_Project/PrDM_Sim_avg_results_2_75_25_x100.txt")
prdm_results_9010 <- read.table("~/Google Drive/Blacknose_Paternity_Project/PrDM_Sim_avg_results_2_90_10_x100.txt")
# average PrDM across simulations 
sim_average5050 <- colMeans(prdm_results_5050)
sim_average7525 <- colMeans(prdm_results_7525)
sim_average9010 <- colMeans(prdm_results_9010)
#organize data for plotting
prdm_5050 <- melt(sim_average5050)
prdm_5050 <- prdm_5050 %>% mutate(Num_loci = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21), Skew = "50:50")
prdm_7525 <- melt(sim_average7525)
prdm_7525 <- prdm_7525 %>% mutate(Num_loci = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21), Skew = "75:25") 
#prdm_9010 <- melt(sim_average9010)
#prdm_9010 <- prdm_9010 %>% mutate(Num_loci = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21), Skew = "90:10") 
#prdm_final <- rbind(prdm_5050, prdm_7525, prdm_9010) don't wan't 90:10 skew 
prdm_final <- rbind(prdm_5050, prdm_7525)

```


```{r PrDM plot}
tiff("Figure_3.tiff", height = 4, width = 6, units = "in", res = 600)
ggplot(prdm_final, aes(x = Num_loci, y = value, group = Skew)) +
  geom_point(aes(shape = Skew)) + 
  xlab("Number of loci") + 
  ylab("PrDM") +
  theme_classic() +
  theme(axis.text=element_text(size=12), axis.title=element_text(size=14))
dev.off()

```




# Atlantic vs Keys Simulation

Simulation to account for uneven sample size between keys and atlantic 

```{r Keys vs Atlantic paternity }
prob_MP1<-0.63 #Chance of multiple paternity 
prob_MP2 <- 0.74

how_many_multiple_fathers<-function(prob_MP1){
  litters<-sample(c('MP','SP'),8,replace=T,prob=c(prob_MP1,(1-prob_MP1)))
  sum(litters=='MP')
}


sim_MP1<-replicate(100000,how_many_multiple_fathers(prob_MP1))
sum(sim_MP1==8)/100000

how_many_multiple_fathers<-function(prob_MP2){
  litters<-sample(c('MP','SP'),8,replace=T,prob=c(prob_MP2,(1-prob_MP2)))
  sum(litters=='MP')
}


sim_MP2<-replicate(100000,how_many_multiple_fathers(prob_MP2))
sum(sim_MP2==8)/100000
```

## Bernarnd's Test

Install/load packages

```{r}
#install.packages("Barnard")
library(Barnard)
```

Perform test

```{r }
AC_test_pooled <- barnard.test(14,8,5,0, dp = 0.001, pooled = TRUE)
AC_test_unpooled <- barnard.test(14,8,5,0, dp = 0.001, pooled = FALSE)

C_test_pooled <- barnard.test(12,8,7,0, dp = 0.001, pooled = TRUE)
C_test_unpooled <- barnard.test(12,8,7,0, dp = 0.001, pooled = FALSE)
```

Use pooled results, two-sided. 

# Sample Map 

```{r Load  map data}
# Lat/Lon Data for Map
map_data <- read.csv("~/Google Drive/Blacknose_Paternity_Project/Data/LatLong_Map.csv", stringsAsFactors=FALSE)
```

```{r Create Map}
tiff("Figure_1.tiff", height = 4, width = 5, units = "in", res = 600)
map("usa", xlim=c(-91,-76), ylim=c(24,34), col="grey85", fill=TRUE, resolution=0, add=FALSE) #add US base
map("state", interior=TRUE, boundary = FALSE, xlim=c(-91,-76), ylim=c(24,34), col="grey40", add=TRUE) # add state lines
text(x=state.center$x, y=state.center$y, state.abb, cex = 0.6) #add state abbreviation labels
text(-87, 27.5, "Gulf of Mexico", cex=.7) #label water
text(-78, 30, "Atlantic", cex =.7)
text(-78, 29.5, "Ocean", cex = .7)
points(map_data$Lon[1:19], map_data$Lat[1:19], pch=19, col="black", cex=0.5) #add Atlantic location points
points(map_data$Lon[20:27], map_data$Lat[20:27], pch=15, col="black", cex=0.5) #add Keys location points
maps::map.scale(-90.5, 25, relwidth = 0.25, metric = TRUE, ratio=FALSE, cex=0.6) #Add scalebar. GIStools also has a map.scale function that masks the maps package function, want to use maps package 
north.arrow(xb=-76.5, yb=32.5, len=0.35, cex.lab= .5, lab="N") #add north arrow
map.axes(cex.axis = 0.6) #add lat/lon scale around map
dev.off() 
```

# Atlantic vs Keys Litter Size and Num Sires Comparison

```{r Load litter data}
sires_litters <- read.csv("~/Google Drive/Blacknose_Paternity_Project/Data/NumSires_LitterSize.csv")
```

```{r Look at distributions and test for normality}
hist(sires_litters$Min_Sires[sires_litters$Location=="Atlantic"])
shapiro.test(sires_litters$Min_Sires[sires_litters$Location=="Atlantic"])
hist(sires_litters$Max_Sires[sires_litters$Location=="Atlantic"])
shapiro.test(sires_litters$Max_Sires[sires_litters$Location=="Atlantic"])
hist(sires_litters$Litter_Size[sires_litters$Location=="Atlantic"])
shapiro.test(sires_litters$Litter_Size[sires_litters$Location=="Atlantic"])


hist(sires_litters$Min_Sires[sires_litters$Location=="Keys"])
#shapiro.test(sires_litters$Min_Sires[sires_litters$Location=="Keys"]) #All the same value so nothing to test
hist(sires_litters$Max_Sires[sires_litters$Location=="Keys"])
shapiro.test(sires_litters$Max_Sires[sires_litters$Location=="Keys"])
hist(sires_litters$Litter_Size[sires_litters$Location=="Keys"])
shapiro.test(sires_litters$Litter_Size[sires_litters$Location=="Keys"])

```

```{r two sample t test}
t.test(sires_litters$Min_Sires[sires_litters$Location=="Atlantic"], sires_litters$Min_Sires[sires_litters$Location=="Keys"])
t.test(sires_litters$Max_Sires[sires_litters$Location=="Atlantic"], sires_litters$Max_Sires[sires_litters$Location=="Keys"])
t.test(sires_litters$Litter_Size[sires_litters$Location=="Atlantic"], sires_litters$Litter_Size[sires_litters$Location=="Keys"])
```

```{r Wilcoxon Rank-Sum Test, message=FALSE, warning=FALSE}

wilcox_minSires <- wilcox.test(Min_Sires ~ Location, data = sires_litters, paired = FALSE)
wilcox_maxSires <- wilcox.test(Max_Sires ~ Location, data = sires_litters, paired = FALSE)
wilcox_litterSize <- wilcox.test(Litter_Size ~ Location, data = sires_litters, paired = FALSE)

print(wilcox_minSires)
print(wilcox_maxSires)
print(wilcox_litterSize)

```